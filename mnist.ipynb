{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#retrieval data\n",
    "(train_images,train_labels), (test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshaping of data\n",
    "but before reshaping, we will try to see, the parameters of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((train_images.shape[0], train_images.shape[1]*train_images.shape[2]))\n",
    "print(train_images.shape)\n",
    "test_images = test_images.reshape((test_images.shape[0], test_images.shape[1]*test_images.shape[2]))\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, now we know that, the pixels values, stay between 0 and 255, and this range of value, have and impact to the model perfomance. For resolving this problem we are dividing pixels values by 255 to have value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after normalization of data, we are creating the network architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the first layer\n",
    "(28*28,) on met la virgule apres car c'est un tuple\n",
    "\n",
    "512 is the number of neurone of the first layers, so the numbers of output \n",
    "\n",
    "relu is the activation fonction\n",
    "\n",
    "when you create first layers, you have the obligation the give the shape of the output\n",
    "\n",
    "### for the second layer\n",
    ">its the same with the first, but now, we don't have output because keras calculate\n",
    "\n",
    ">directly the shape of input of the others layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models,layers\n",
    "\n",
    "mnist_network = models.Sequential()\n",
    "mnist_network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "mnist_network.add(layers.Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label's preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_network.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fiting of the network, to build a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part we are using .fit procedure, which fit the weight parameters, in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we have fonction's parameters (epoch and batch batch_size)\n",
    "\n",
    "_one epoch_ is one complete pass throught in the entire training dataset. During one epoch the model see all the training examples.\n",
    "\n",
    "_batch_ _size_ is the number of element in the training part which are taking to calculate the gradient, and and update the weight, in the models . and after each trainnig examples the model fit the weigth also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.4351\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.1135\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9784 - loss: 0.0721\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0502\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x755c8f48b470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_network.fit(train_images,train_labels,epochs=5,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after the training part, and the fiting of weights, we have and interogation ? \n",
    "The model wich build was good ?\n",
    "to answer this question, we will are using bellow the data test, to see the accuracy, in other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0759\n",
      "test_accuracy : 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = mnist_network.evaluate(test_images,test_labels)\n",
    "print('test_accuracy :',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, accuracy is so hight, and it's a good thing, because depend of difefrent metrics, when the accuracy was superior than 85%, the model was good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you finish to build your model, you have obligation to test it with real data. In this part we do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "La classe prédite est : 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# loading image\n",
    "img_path = 'test_img.png'  # replace by the image path\n",
    "img = image.load_img(img_path, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "\n",
    "# convert image in numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# colors inversion if it's necessary (the MNIST image are black on withe)\n",
    "img_array = 255 - img_array\n",
    "\n",
    "# reshaping image in the good size\n",
    "img_array = img_array.reshape((1, 28 * 28))\n",
    "\n",
    "# normalize the pixels values\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# use model to predict the image's class\n",
    "prediction = mnist_network.predict(img_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "print(f\"La classe prédite est : {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
